redis:
  # Local development defaults to localhost; Docker Compose overrides to redis:6379.
  addr: "localhost:6379"
  pool_size_multiplier: 10
  min_idle_conns: 5
  dial_timeout: 5s
  read_timeout: 3s
  write_timeout: 3s
  max_retries: 3

worker:
  count: 16
  heartbeat_ttl: 30s
  max_retries: 3
  backoff:
    base: 500ms
    max: 10s
  priorities: ["high", "low"]
  queues:
    high: "jobqueue:high_priority"
    low:  "jobqueue:low_priority"
  processing_list_pattern: "jobqueue:worker:%s:processing"
  heartbeat_key_pattern:  "jobqueue:processing:worker:%s"
  completed_list: "jobqueue:completed"
  dead_letter_list: "jobqueue:dead_letter"
  brpoplpush_timeout: 1s

producer:
  scan_dir: "./data"
  include_globs: ["**/*"]
  exclude_globs: ["**/*.tmp", "**/.DS_Store"]
  default_priority: "low"
  high_priority_exts: [".pdf", ".docx", ".xlsx", ".zip"]
  rate_limit_per_sec: 100
  rate_limit_key: "jobqueue:rate_limit:producer"

circuit_breaker:
  failure_threshold: 0.5
  window: 1m
  cooldown_period: 30s
  min_samples: 20

observability:
  metrics_port: 9091
  log_level: "info"
  queue_sample_interval: 2s
  tracing:
    enabled: false
    endpoint: ""

exactly_once:
  idempotency:
    enabled: true
    # Keys are composed as {queue}:{tenant}:{key} where key derives from payload hash + headers.
    default_ttl: 24h
    # cleanup_interval controls background removal cadence; expired keys may persist until this runs.
    key_prefix: "idempotency:"
    max_retries: 3
    retry_delay: 100ms
    cleanup_interval: 1h
    batch_size: 100
    storage:
      type: "redis"
      redis:
        key_pattern: "{queue}:idempotency:{tenant}:{key}"  # First write wins; retries reuse stored result.
        hash_key_pattern: "{queue}:idempotency:{tenant}"
        use_hashes: true
        compression: false

  outbox:
    enabled: false  # Requires database setup; see docs/outbox.md for schema.
    # Example DSN: "postgresql://queue:queuepass@localhost:5432/queue_outbox?sslmode=disable"
    dsn: ""
    table: "outbox_events"  # Columns: id (UUID), payload JSONB, created_at, published_at
    publish_query: "SELECT id, payload FROM outbox_events WHERE published_at IS NULL ORDER BY created_at LIMIT $1"
    poll_interval: 5s
    batch_size: 50
    max_retries: 5
    cleanup_interval: 24h
    cleanup_after: 168h  # 7 days
    retry_backoff:
      initial_delay: 1s
      max_delay: 30m
      multiplier: 2.0
      jitter: true
    publishers: []

  metrics:
    enabled: true
    collection_interval: 30s
    histogram_buckets: [0.001, 0.01, 0.1, 1, 10]
    cardinality_limit: 1000
