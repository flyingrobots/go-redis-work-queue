---
title: e35da518e543d331abf0b57fa939d682d39f5a88.md (chunk 004)
description: Preserved review artifacts and rationale.
audience: [contributors]
domain: [quality]
tags: [review]
status: archive
---

# Code Review Feedback

<!-- chunk-progress:begin -->
```text
██████████░░░░░░░░░░░░░░░░░░░░ 33.3% (10/30 addressed)
```
<!-- chunk-progress:end -->

| Date | Agent | SHA | Branch | PR |
|------|-------|-----|--------|----|
| 2025-09-16 | CodeRabbit | `e35da518e543d331abf0b57fa939d682d39f5a88` | [unify/chaos-main](https://github.com/flyingrobots/go-redis-work-queue/tree/unify/chaos-main "flyingrobots/go-redis-work-queue:unify/chaos-main") | [PR#3](https://github.com/flyingrobots/go-redis-work-queue/pull/3) |

## Instructions

Please carefully consider each of the following feedback items, collected from a GitHub code review.

Please act on each item by fixing the issue, or rejecting the feedback. Please update this document and fill out the information below each feedback item by replacing the text surrounded by curly braces.

### deployments/kubernetes/monitoring.yaml:220

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/kubernetes/monitoring.yaml around line 220, the file is missing a
trailing newline at EOF; add a single newline character at the end of the file
so the final line terminator is present and the file ends with a newline.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 6 | Verified the manifest now ends with a single newline to satisfy linters. |
>
> ## Lesson Learned
>
> Even tiny formatting issues like missing newlines can break CI linters.
>
> ## What did you do to address this feedback?
>
> Appended a trailing newline to `deployments/kubernetes/monitoring.yaml` so the file terminates cleanly.
>
> ## Regression Avoidance Strategy
>
> Ensure editors keep "append newline at EOF" enabled when editing manifests.
>
> ## Notes
>
> No functional changes; formatting only.

### deployments/README.md:44

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/README.md around lines 39-44 (and also update occurrences at
165-170), the docs inconsistently reference /health, /healthz and /readyz;
choose the Kubernetes conventions and make them consistent: use /healthz for
liveness and /readyz for readiness across the entire document, update the curl
examples and any runbook references accordingly, and verify no other places
still reference /health (or swap meanings) so probes and examples match the
chosen endpoints.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | README and deployment probes now consistently use `/healthz` and `/readyz`. |
>
> ## Lesson Learned
>
> Aligning docs and probes on Kubernetes conventions avoids operator confusion.
>
> ## What did you do to address this feedback?
>
> Updated `deployments/README.md` to document `/healthz` and `/readyz` and adjusted the admin API deployment liveness/readiness probes to hit those paths.
>
> ## Regression Avoidance Strategy
>
> Include endpoint checks in documentation reviews when adding new health probes.
>
> ## Notes
>
> No code changes outside of manifest probe paths.

### deployments/README.md:88

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/README.md around lines 80 to 88, the README claims a rate limit
of “100 rpm, burst 20” but no environment variables or flags are documented to
control those values; add explicit env config entries for the rate limiter
(e.g., RATE_LIMIT_RPM, RATE_LIMIT_BURST, optionally RATE_LIMIT_WINDOW_SECONDS
and RATE_LIMIT_ENABLED) with clear descriptions and sensible defaults (100, 20,
60, true), specify expected types (integer/boolean), and note that the
application should read these envs to configure the limiter; update the table to
include these variables, their descriptions and defaults so users can actually
tune the rate limiting behavior.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Rate limiter environment variables and defaults are now documented. |
>
> ## Lesson Learned
>
> Config docs need to specify the knobs operators can actually turn.
>
> ## What did you do to address this feedback?
>
> Added `RATE_LIMIT_RPM`, `RATE_LIMIT_BURST`, `RATE_LIMIT_WINDOW_SECONDS`, and `RATE_LIMIT_ENABLED` to the README’s environment table with defaults and usage guidance.
>
> ## Regression Avoidance Strategy
>
> Keep the env var table in sync with new limiter options when code changes land.
>
> ## Notes
>
> Documentation-only change.

### deployments/README.md:100

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/README.md around lines 93 to 100, the current example uses
kubectl create secret ... --from-literal with real tokens which leaks secrets to
shell history and CI logs; update the docs to instruct creating secrets from
files or stdin (store tokens in files with restrictive permissions or pass via
pipe/stdin), or generate a YAML manifest with kubectl --dry-run=client -o yaml
and apply that manifest, and emphasise not to paste secrets directly into
shell/CI logs and to use environment variables or secret managers in CI.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Secret creation docs now use file-based inputs and recommend dry-run manifests. |
>
> ## Lesson Learned
>
> Copy-pasting secrets into terminals is an easy way to leak credentials.
>
> ## What did you do to address this feedback?
>
> Reworked the README to show `kubectl create secret` with `--from-file`, added a dry-run apply example, and documented the need to load values from secure sources.
>
> ## Regression Avoidance Strategy
>
> Keep security guidance alongside secret management docs whenever commands change.
>
> ## Notes
>
> Documentation-only change.

### deployments/README.md:100

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/README.md around lines 95–100 the secret is created with -n
work-queue but other admin-api manifests use -n redis-work-queue, causing
namespace drift; pick the cluster's canonical namespace (confirm with kubectl
get namespaces or team docs) and make it consistent across all affected files:
either change this README secret to -n redis-work-queue, or update every
manifest/script that uses redis-work-queue to work-queue. Specifically update
deployments/README.md; deployments/admin-api/* (k8s-deployment.yaml,
k8s-redis.yaml, monitoring.yaml, deploy.sh); deployments/kubernetes/*
(admin-api-deployment.yaml, rbac-token-service-deployment.yaml,
monitoring.yaml); deployments/scripts/* (setup-monitoring.sh,
test-staging-deployment.sh); and update docs/monitoring to reflect the chosen
namespace. Ensure all kubectl commands, YAML metadata.namespace fields, and Helm
values (if any) match the chosen namespace and run a dry validation (kubectl
apply --server-dry-run or kubeval) to confirm no mismatches remain.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 7 | All admin API manifests and deployment defaults now point to the `work-queue` namespace. |
>
> ## Lesson Learned
>
> Divergent namespaces across manifests and scripts break secret and alert wiring.
>
> ## What did you do to address this feedback?
>
> Updated `deployments/admin-api/k8s-deployment.yaml`, `deployments/admin-api/k8s-redis.yaml`, and `deployments/admin-api/deploy.sh` to declare and target the `work-queue` namespace consistently.
>
> ## Regression Avoidance Strategy
>
> Add namespace verification to deployment review checklists to prevent drift.
>
> ## Notes
>
> Supporting docs already referenced `work-queue`; no additional changes required.

### deployments/README.md:148

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/README.md around lines 146-148, the docs mention rate limits but
omit that /metrics must not be internet-facing; update the notes to state
explicitly that the metrics endpoint must be exposed only via a ClusterIP-only
Service (no Ingress/LoadBalancer) and protected with a NetworkPolicy restricting
access to Prometheus scrape targets, and document that scraping should be done
via a ServiceMonitor or Prometheus scrape config targeting the ClusterIP service
only.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | README now warns to keep `/metrics` internal-only with NetworkPolicies. |
>
> ## Lesson Learned
>
> Observability endpoints can leak data if exposed; remind operators up front.
>
> ## What did you do to address this feedback?
>
> Added guidance that `/metrics` should stay behind a ClusterIP service, protected by NetworkPolicies, and scraped via ServiceMonitor/Prometheus configs only.
>
> ## Regression Avoidance Strategy
>
> Keep security notes alongside monitoring instructions when new endpoints are documented.
>
> ## Notes
>
> Documentation-only change.

### docs/00_assessment.md:21

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/00_assessment.md around lines 20–21, the doc currently pins "go-redis
v8" — update wording to "go-redis v9 (v9+)" and add a concise migration
checklist that lists the breaking changes to account for (pipelines not
thread-safe; changed timeout/cancel behavior; Pipeline.Close/WithContext
removed; option renames MaxConnAge→ConnMaxLifetime and
IdleTimeout→ConnMaxIdleTime; connection reaper removal in favor of MaxIdleConns;
redis.Z type change from *Z→Z; reworked hooks API including DialHook; RESP3
behavior differences). Also append a short upgrade plan (steps: upgrade
dependency in lockfile, run tests, audit pipeline usages and option names,
update hooks and types, run performance/RESP3 smoke tests) plus a rollback
justification (pin v8 in lockfile and revert dependency if issues) or explicit
justification for staying on v8. Ensure the text stays brief, actionable, and
includes a checklist and upgrade/rollback plan.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Assessment now highlights go-redis v9 and documents migration/rollback steps. |
>
> ## Lesson Learned
>
> Version upgrades need actionable checklists, not just a version bump.
>
> ## What did you do to address this feedback?
>
> Updated the assessment to reference go-redis v9 and added a migration checklist covering pipeline safety, option renames, hooks, RESP3 behavior, plus explicit upgrade and rollback plans.
>
> ## Regression Avoidance Strategy
>
> Keep dependency notes current whenever the Redis client is upgraded.
>
> ## Notes
>
> Documentation change only.

### docs/07_test_plan.md:29

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/07_test_plan.md around lines 27 to 29, replace the vague "Chaos (where
feasible in CI)" note with a deterministic list of fault-injection scenarios and
explicit pass/fail criteria: enumerate concrete failures (e.g., Redis SIGSTOP
for 30s, introduce 200ms p95 latency using tc netem on Redis port, inject 5% TCP
connection resets via iptables or tc loss), provide exact commands or CI steps
to run each injection (so they can be replayed in CI or locally), define how
long each injection should run and the sequence/timing, and state clear
pass/fail criteria for each (e.g., service stays healthy, no data loss, retries
succeed within X seconds, error rate < Y%) so reviewers and CI can
deterministically validate outcomes.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Chaos section now lists explicit failures, commands, durations, and pass/fail criteria. |
>
> ## Lesson Learned
>
> Chaos testing must be prescriptive to be trustworthy and automatable.
>
> ## What did you do to address this feedback?
>
> Replaced the vague chaos note with three deterministic scenarios (SIGSTOP, tc latency, connection resets) each with commands, timing, and success criteria.
>
> ## Regression Avoidance Strategy
>
> Keep CI chaos jobs tied to this checklist so new scenarios stay reproducible.
>
> ## Notes
>
> Documentation-only change.

### docs/07_test_plan.md:45

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/07_test_plan.md around lines 41 to 45, the benchmark notes lack
reproducibility details; update the test plan to pin the GH runner size (exact
VM type/VM image), specify the exact Go version used, set and document
GOMAXPROCS (and recommend exporting it in the runner), fix and export the RNG
seed used by the synthetic job producer, document CPU governor/settings used
during runs, and ensure each run prints the commit SHA (and any build
tags/flags) and exports the seed so results can be reproduced; include these
fields in the Reporting section so CPU/memory/Redis/queue metrics are captured
alongside runner size, GOMAXPROCS, seed, CPU governor, and Go version.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Benchmark section now specifies runner type, Go version, GOMAXPROCS, seed, and reporting fields. |
>
> ## Lesson Learned
>
> Performance numbers are only meaningful when the execution environment is locked down.
>
> ## What did you do to address this feedback?
>
> Documented the GitHub runner size, required Go version, `GOMAXPROCS`, deterministic seed, CPU governor settings, and result reporting fields (commit SHA, build tags, metrics) in the test plan.
>
> ## Regression Avoidance Strategy
>
> Keep bench job templates aligned with this checklist so env drift surfaces quickly.
>
> ## Notes
>
> Documentation-only change.

### docs/api/anomaly-radar-slo-budget.md:176

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/api/anomaly-radar-slo-budget.md around lines 124 to 176, the duration
field "window" is ambiguous as currently shown ("720h0m0s"); update the docs to
explicitly state that durations are encoded as Go time.Duration strings and list
accepted formats (e.g., "72h", "720h0m0s", "30m", "1h30m", "1500ms"), include a
short note about parsing behavior (supports negative values and sub-second units
like "1500ms" or "1.5s"), and add one or two alternate example values in the
JSON response to demonstrate valid variants so downstream clients know how to
parse them.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Duration fields now document Go `time.Duration` syntax with varied examples. |
>
> ## Lesson Learned
>
> Clients need explicit duration format guidance to avoid parsing bugs.
>
> ## What did you do to address this feedback?
>
> Updated the SLO budget response to show alternate duration examples and added prose explaining accepted `time.Duration` formats (including sub-second and signed values).
>
> ## Regression Avoidance Strategy
>
> Mirror future duration fields with the same explanatory note in API docs.
>
> ## Notes
>
> Documentation-only change.

### docs/api/anomaly-radar-slo-budget.md:217

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/api/anomaly-radar-slo-budget.md around lines 186 to 217, the config
endpoint documentation is missing required Authentication/Authorization details
for this admin surface; update the endpoint docs to include an
"Authentication/Authorization" block that states the endpoint requires admin
scope and specifies the auth scheme (Bearer JWT) consistent with the Admin API
docs, include required header (Authorization: Bearer <token>), required
roles/scopes (e.g., "admin" or specific scope name used by the Admin API), and a
short example note on denied responses (401/403) so readers know auth is
mandatory.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Endpoint doc now calls out Bearer auth requirements and 401/403 behaviours. |
>
> ## Lesson Learned
>
> Every admin surface needs clearly documented auth requirements.
>
> ## What did you do to address this feedback?
>
> Added an explicit Authentication/Authorization block describing the required admin-scoped bearer token and error responses.
>
> ## Regression Avoidance Strategy
>
> Ensure new endpoint docs include auth sections by default.
>
> ## Notes
>
> Doc-only update.

### docs/api/canary-deployments.md:19

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
```text
In docs/api/canary-deployments.md around lines 15 to 19, the authentication
headers listed are inconsistent with the rest of the repo (Bearer + X-API-Key).
Update the section to standardize on Authorization: Bearer <token> as the
primary method, replace X-API-Key with the repository-preferred alias
X-API-Token (if an alias is needed), and add one sentence clarifying semantics
and precedence (Authorization header takes precedence over X-API-Token when both
are present). Ensure the examples and header names in this block are changed
accordingly.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Auth section now aligns with repo conventions (Bearer primary, `X-API-Token` alias). |
>
> ## Lesson Learned
>
> Consistent auth guidance prevents conflicting client implementations.
>
> ## What did you do to address this feedback?
>
> Rewrote the authentication section to emphasise bearer tokens, note the optional `X-API-Token`, and document precedence when both headers appear.
>
> ## Regression Avoidance Strategy
>
> Mirror this wording in other API docs to maintain consistency.
>
> ## Notes
>
> Documentation-only change.

### docs/api/canary-deployments.md:345

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
```text
In docs/api/canary-deployments.md around lines 303–345, the JSON mixes units
(error_rate shown as 0.96 while success_rate is 99.04) — pick a single
convention and make fields explicit; update the schema to use percentage fields
(rename error_rate → error_percent and success_rate → success_percent) and set
their values to (error_count/job_count)*100 and (success_count/job_count)*100
respectively (rounded consistently, e.g., two decimal places), and add a short
comment/inline note in the docs that these fields are percentages to avoid
future confusion.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Metrics examples now expose `error_percent`/`success_percent` and clarify 0–100 scaling. |
>
> ## Lesson Learned
>
> Mixed units confuse consumers; always document scale explicitly.
>
> ## What did you do to address this feedback?
>
> Renamed the metrics fields to `*_percent`, updated all JSON examples, and added notes explaining the 0–100 percentage convention.
>
> ## Regression Avoidance Strategy
>
> Apply the same naming to future metrics schemas to keep units consistent.
>
> ## Notes
>
> Documentation-only change.

### docs/api/canary-deployments.md:592

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
```text
In docs/api/canary-deployments.md around lines 556 to 592, the Deployment Object
"id" field is underspecified; update the schema and prose to explicitly state
the expected ID format (e.g., "uuid" v4 or "ULID"), allowed characters and
length, give a concrete example, and indicate that the server validates IDs and
will return HTTP 400 on invalid IDs; add a short note on the validation rules
(regex or exact format), whether IDs are case-sensitive, and link to the API
error response shape for 400 validation errors.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Deployment object now shows a ULID example and documents validation regex + 400 behaviour. |
>
> ## Lesson Learned
>
> Explicit identifier formats reduce client guesswork and error handling surprises.
>
> ## What did you do to address this feedback?
>
> Replaced the placeholder ID with a ULID example and documented the required regex, case sensitivity, and 400 response on invalid IDs.
>
> ## Regression Avoidance Strategy
>
> Include identifier format notes in future schema docs.
>
> ## Notes
>
> Doc update only.

### docs/api/capacity-planning-api.md:158

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/api/capacity-planning-api.md around lines 146 to 158 the example calls
calc.Calculate(..., metrics) but never declares metrics, causing copy-paste
compile errors; either add a minimal declaration such as metrics :=
capacityplanning.Metrics{ /* fill required fields */ } immediately before the
call, or remove the metrics parameter from the example call and adjust the
argument list accordingly so the snippet compiles.
```

{response}

### docs/api/capacity-planning-api.md:318

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/api/capacity-planning-api.md around lines 311 to 318, the import uses a
hardcoded placeholder module path "github.com/yourorg/..." which will mislead
users; update the import to either the repository's actual Go module path or
replace it with a neutral placeholder comment (e.g., // replace with your module
path) and show an example like module/path/to/automatic-capacity-planning so
readers know to substitute their own module path; ensure the docs clearly state
to replace the placeholder with the user's real module path.
```

{response}

### docs/api/exactly-once-admin.md:321

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/api/exactly-once-admin.md around lines 299 to 321, replace the literal
"YOUR_TOKEN" used in the curl examples with a clearly identifiable placeholder
(e.g. <YOUR_API_TOKEN_HERE> or ${API_TOKEN}) and add a brief note in the
examples that this must be substituted with a real token or read from an
environment variable; update all four curl snippets to use the chosen
placeholder consistently so readers cannot copy-paste a literal string by
mistake.
```

{response}

### docs/PRD.md:168

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/PRD.md around lines 162-168 the current metric definition
queue_length{queue=...} risks unbounded label cardinality; update the spec to
require limiting/sanitizing queue labels by adding a new config entry (e.g.
metrics.allowed_queues: list of permitted queue names) and a fallback strategy
(hash or bucket remaining queues into a small fixed set or use a generic "other"
label), describe how the exporter/collector will emit metrics (only allowed
queue labels appear verbatim; disallowed names are hashed/bucketed or
aggregated), and include default config values and expected cardinality behavior
in the doc.
```

{response}

### .claude/agents/feature-enhancer.md:12

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
`
In .claude/agents/feature-enhancer.md around lines 8 to 12 (and similar issues
at 20-36, 44-74, 80-126, 190-212, 252-269), the markdown has lint failures
(incorrect heading spacing, missing blank lines around fenced code blocks,
inconsistent fenced code ticks, trailing newline missing). Run make mdlint-fix
and commit the result; if fixing manually, ensure headings have a blank line
above, add a blank line before and after every
```

{response}

### AGENTS.md:193

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In AGENTS.md around lines 183 to 193, replace the fake placeholder link
"https://fake.com" and any "(to PR)" text with the actual PR or issue URLs (or
remove them entirely if no real links exist), and update the nonstandard
admonition syntax "[!info]-" to the proper GitHub-flavored blockquote admonition
format such as "> [!NOTE]" or "> [!WARNING]" (without the trailing hyphen),
ensuring links use valid markdown link syntax and no placeholder text remains.
```

{response}

### cmd/tui/main.go:31

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In cmd/tui/main.go around line 31, the FlagSet is created with flag.ExitOnError
which calls os.Exit on parse errors and bypasses your function's error handling;
change the creation to use flag.ContinueOnError so Parse returns an error
instead, then call fs.Parse(os.Args[1:]) and handle/return that error
consistently with the rest of the function (optionally set fs.SetOutput to
discard or a logger if you want to suppress default printed usage).
```

{response}

### cmd/tui/main.go:43

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In cmd/tui/main.go around line 43, the error returned by fs.Parse(os.Args[1:])
is being discarded; instead capture the error, check if it's non-nil, write the
error message to stderr (and/or call fs.Usage()), and exit with a non-zero
status (e.g., os.Exit(2>) or return the error) so parsing failures are properly
reported and the process terminates.
```

{response}

### cmd/tui/main.go:66

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In cmd/tui/main.go around lines 64-66, the code pings Redis and merely logs on
error but continues running with a broken connection; change this to fail fast:
on Ping error write the error to stderr (or process logger) and exit the process
with a non-zero status (or return the error from main) so the TUI does not
proceed with an invalid Redis client; alternatively implement a small
retry/backoff loop before exiting if transient errors are expected, but do not
allow execution to continue when Ping ultimately fails.
```

{response}

### cmd/tui/main.go:68

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In cmd/tui/main.go around line 68, the TODO leaves many CLI flags un-wired
(redisURL, cluster, namespace, readOnly, metricsAddr, theme, fps) so the TUI
starts without required runtime options; fix by reading these flags from the
root/Cobra command or shared config struct and passing them into the TUI
initializer: add parameters on the TUI options/ctor for
redisURL/cluster/namespace (used to construct the redis/backend client),
readOnly (toggle input/editing and backend write operations), metricsAddr
(start/forward metrics collection if non-empty), and theme/fps (apply to
renderer/refresh loop); ensure the flags are defined and defaulted at command
setup and validate/convert types before constructing the TUI, then remove the
TODO.
```

{response}

### deployments/admin-api/deploy.sh:10

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/deploy.sh around lines 1 to 10, the script uses weak
bash settings and unquoted variable expansions; update the shebang area to
enable strict mode by replacing the current set -e with set -Eeuo pipefail, and
ensure all variable usages in the script are quoted (e.g., use "$NAMESPACE",
"$APP_NAME", "${ENVIRONMENT}", "${VERSION}" wherever referenced) to prevent
word-splitting and undefined-variable errors; also ensure positional defaults
remain as shown but are safely assigned (retain ENVIRONMENT="${1:-staging}" and
VERSION="${2:-latest}").
```

{response}

### deployments/admin-api/deploy.sh:43

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/deploy.sh around lines 31 to 43, the docker tag/push
steps use unquoted variable expansions and assume a good registry value which
can break with spaces, empty vars, or missing namespace; update to quote all
variable expansions (e.g. "${APP_NAME}" "${VERSION}" "${REGISTRY_URL}" ),
validate or default DOCKER_REGISTRY and DOCKER_NAMESPACE explicitly before use
(fail fast if missing), construct a fully qualified repository string like
"${REGISTRY_URL%/}/${DOCKER_NAMESPACE:-your-namespace}/${APP_NAME}:${VERSION}"
to avoid double slashes or implicit Docker Hub quirks, and use that quoted
repository value for both docker tag and docker push; also consider requiring
docker login before push (or check LOGIN env) and exit with an error if push
fails.
```

{response}

### deployments/admin-api/deploy.sh:61

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/deploy.sh around lines 49 to 61, the script creates the
${NAMESPACE} but then applies manifests without specifying that namespace;
update the kubectl apply invocations to target the created namespace by adding
-n ${NAMESPACE} (or --namespace=${NAMESPACE}) to the redis and admin-api apply
commands so both kubectl apply -f deployments/admin-api/k8s-redis.yaml and
kubectl apply -f deployments/admin-api/k8s-deployment.yaml run against the
intended namespace; keep the existing kubectl wait which already uses -n
${NAMESPACE}.
```

{response}

### deployments/admin-api/deploy.sh:85

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/deploy.sh around lines 73-85 (and also apply same
change to lines 113-116), the script currently starts a kubectl port-forward in
the "local" branch without ensuring it is cleaned up and also runs port-forward
in Docker "local" mode; update the script so it only performs kubectl
port-forward when running against a k8s cluster (not when ENVIRONMENT indicates
Docker/local-Docker), capture the background PID immediately, set a trap on EXIT
(and SIGINT/SIGTERM) to kill the port-forward if it was started, and ensure any
sleep/wait uses a small readiness check rather than a blind sleep; apply the
identical guard+trap pattern to the other location (lines 113-116).
```

{response}

### deployments/admin-api/deploy.sh:177

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/deploy.sh around lines 170-177, replace the deprecated
docker-compose usage with the modern `docker compose` subcommand and add a
pre-check that verifies `docker compose` is available: implement a small check
(e.g., run `docker compose version` or `command -v docker` + `docker compose
version` and test its exit code) before the local deploy branch and if the check
fails print a clear error and exit non-zero; then change the local case to call
`docker compose -f deployments/admin-api/docker-compose.yaml up -d` (or bail if
unavailable).
```

{response}

### deployments/admin-api/docker-compose.yaml:28

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In deployments/admin-api/docker-compose.yaml around line 28, the JWT_SECRET is
set to a weak default which is insecure; remove the hardcoded fallback so the
environment variable must be provided (e.g. change JWT_SECRET=${JWT_SECRET} with
no default), add a tiny validation service or init container that checks
process.env.JWT_SECRET and exits non‑zero if missing, and update the admin-api
service to depend_on that validation service so the stack fails fast when
JWT_SECRET is not supplied; ensure local/dev docs or .env.example instructs how
to provide a strong secret.
```

{response}
