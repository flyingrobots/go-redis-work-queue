---
title: e35da518e543d331abf0b57fa939d682d39f5a88.md (chunk 002)
description: Preserved review artifacts and rationale.
audience: [contributors]
domain: [quality]
tags: [review]
status: archive
---

# Code Review Feedback

<!-- chunk-progress:begin -->
```text
████████████████████░░░░░░░░░░ 66.7% (20/30 addressed)
```
<!-- chunk-progress:end -->

| Date | Agent | SHA | Branch | PR |
|------|-------|-----|--------|----|
| 2025-09-16 | CodeRabbit | `e35da518e543d331abf0b57fa939d682d39f5a88` | [unify/chaos-main](https://github.com/flyingrobots/go-redis-work-queue/tree/unify/chaos-main "flyingrobots/go-redis-work-queue:unify/chaos-main") | [PR#3](https://github.com/flyingrobots/go-redis-work-queue/pull/3) |

## Instructions

Please carefully consider each of the following feedback items, collected from a GitHub code review.

Please act on each item by fixing the issue, or rejecting the feedback. Please update this document and fill out the information below each feedback item by replacing the text surrounded by curly braces.

### docs/03_milestones.md:8

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/03_milestones.md around lines 6 to 8, the milestone entries lack
assigned owners/DRIs; add an owner for each milestone (name, role, contact) and
a backup/secondary DRI, and include a one-line responsibility statement per
owner. Update the milestones list or table to add an "Owner / DRI" column or a
subheading under each milestone with the owner's name, role, email/Slack handle,
and their specific accountability (e.g., delivery lead, QA lead), and ensure
dependencies or decision gates note who is responsible for sign-off.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Every milestone now lists owner, backup DRI, and responsibility statement. |
>
> ## Lesson Learned
>
> Explicit accountability in milestones clarifies who can unblock go/no-go decisions.
>
> ## What did you do to address this feedback?
>
> Added owner/backup details and concise responsibility blurbs for milestones 1–7.
>
> ## Regression Avoidance Strategy
>
> Continue updating milestone ownership whenever leadership assignments change.
>
> ## Notes
>
> Doc edit only; no tests.

### docs/04_sprint_plans.md:8

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/04_sprint_plans.md around lines 5 to 8, replace the ambiguous term
"bi-weekly sprints" with the explicit phrase "two-week sprints" (and any other
occurrences in this file) so the plan unambiguously states sprint length; update
the sentence to read something like "Four two-week sprints lead to v1.0.0." and
verify surrounding text remains grammatically correct.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 10 | Terminology now states "two-week sprints" explicitly. |
>
> ## Lesson Learned
>
> Plain wording beats ambiguous jargon when documenting cadence.
>
> ## What did you do to address this feedback?
>
> Replaced the lone occurrence of "bi-weekly" with "two-week" in the sprint overview sentence.
>
> ## Regression Avoidance Strategy
>
> Continue reviewing docs for ambiguous cadence phrasing during edits.
>
> ## Notes
>
> Docs-only update; no tests.

### docs/06_technical_spec.md:117

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/06_technical_spec.md around lines 113–117, the reaper section is
hand-wavy: stop inferring original queue from payload and instead persist an
origin_queue field in job metadata; limit SCAN cost by using SCAN/SSCAN with
COUNT plus a per-invocation time budget and randomized jitter between scans to
avoid thundering-herd effects; and perform RPOP/LPUSH re-queue operations inside
a Redis Lua script (EVAL) so list mutation and heartbeat checks are atomic and
consistent. Ensure the spec describes how the reaper reads heartbeat keys, skips
live workers, uses the persisted origin_queue to determine destination list,
enforces a page/time limit per run, and sleeps with jitter between pages.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Spec now details origin queue persistence, bounded SCAN windows with jitter, and Lua-based requeue steps. |
>
> ## Lesson Learned
>
> Reaper expectations must be documented precisely to keep future implementations safe and consistent.
>
> ## What did you do to address this feedback?
>
> Expanded the "Reaper" section and related observability notes in `docs/06_technical_spec.md:112-146` to cover origin queue metadata, capped SCAN/SSCAN sweeps with jitter, Lua scripts for atomic RPOP/LPUSH, and metric/logging requirements.
>
> ## Regression Avoidance Strategy
>
> Keep the spec in sync with reaper behaviour whenever the implementation changes.
>
> ## Notes
>
> None.

### docs/13_release_versioning.md:25

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/13_release_versioning.md around lines 21 to 25, the release checklist
lacks supply-chain verification gates; add a new checklist item requiring an
SBOM, provenance (SLSA/OIDC) attestation, and signed artifacts (cosign) before
release. Update the numbered list to include a clear line such as “4) Ensure
supply-chain artifacts present: SBOM generated, build provenance/SLSA
attestations (e.g. OIDC) available, and release artifacts signed (e.g. cosign)”; 
optionally add brief links or references to existing internal tooling or
standards used for SBOM/provenance/signing and ensure CI blocks release when
these artifacts are missing.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Release checklist now includes an explicit supply-chain verification step. |
>
> ## Lesson Learned
>
> Supply-chain artifacts must be part of the standard release checklist, not tribal knowledge.
>
> ## What did you do to address this feedback?
>
> Added a new checklist entry in `docs/13_release_versioning.md:23-34` covering SBOM export, SLSA/OIDC provenance, and cosign signing before tagging.
>
> ## Regression Avoidance Strategy
>
> Keep the checklist updated alongside CI enforcement so audit requirements remain visible to releasers.
>
> ## Notes
>
> None.

### docs/13_release_versioning.md:31

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/13_release_versioning.md around lines 26 to 31, the current instructions
use a lightweight tag and recommend git push --tags which can push all local
tags; change to recommend creating an annotated or signed tag and pushing only
that single ref. Update the steps to show using git tag -a (or -s) with a
message, then git push origin <tag-name>, replacing the generic --tags flow so
only the new release tag is published.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Release guide now instructs creating annotated tags and pushing the single ref. |
>
> ## Lesson Learned
>
> Protecting tagging steps prevents accidental publication of unintended refs.
>
> ## What did you do to address this feedback?
>
> Updated the tagging instructions in `docs/13_release_versioning.md:27-33` to use `git tag -a …` and `git push origin <tag>` instead of `--tags`.
>
> ## Regression Avoidance Strategy
>
> Keep the release checklist aligned with the tagging process enforced in CI.
>
> ## Notes
>
> None.

### docs/SLAPS/worker-reflections/claude-006-reflection.md:5

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/SLAPS/worker-reflections/claude-006-reflection.md around lines 1 to 5,
the file needs lightweight provenance front matter: add a minimal,
machine-parseable header at the top (e.g., YAML-style) that includes author,
repository name (or URL), and commit hash (and optionally a timestamp), then
retain the existing title and metadata below it; ensure the front matter is
syntactically valid (triple-dashed block) and minimal so downstream tools can
parse author, repo and commit_hash fields.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Added YAML front matter with author, repo, commit hash, and timestamp for provenance. |
>
> ## Lesson Learned
>
> Provenance metadata helps downstream tooling trace reflections back to commits.
>
> ## What did you do to address this feedback?
>
> Prepended a minimal header (`docs/SLAPS/worker-reflections/claude-006-reflection.md:1-6`) containing `author`, `repository`, `commit_hash`, and `timestamp` fields.
>
> ## Regression Avoidance Strategy
>
> Apply the same header pattern to future SLAPS reflection files on creation.
>
> ## Notes
>
> None.

### docs/YOU ARE WORKER 6.rb:4

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/YOU ARE WORKER 6.rb around lines 3 to 4, the README uses vendor-specific
phrasing ("Claude worker"); replace that with a neutral role description (e.g.,
"a worker in the SLAPS task execution system" or "task worker") so the text
reads project-neutral: update the sentence to remove the vendor name and ensure
it still communicates that the role claims and executes tasks for the
go-redis-work-queue project.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Role description now uses vendor-neutral wording and adds safety guidance. |
>
> ## Lesson Learned
>
> Documentation should stay tool-agnostic so processes survive vendor changes.
>
> ## What did you do to address this feedback?
>
> Replaced the introductory sentence and workflow guidance in `docs/YOU ARE WORKER 6.rb:1-28` with vendor-neutral language while clarifying atomic move precautions.
>
> ## Regression Avoidance Strategy
>
> Keep future worker docs vendor-free unless a specific product detail is required.
>
> ## Notes
>
> None.

### docs/YOU ARE WORKER 6.rb:13

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/YOU ARE WORKER 6.rb around lines 6 to 13, the workflow step that tells
workers to "Claim a task by moving it to slaps-coordination/claude-001/" lacks
any caution about mv being non-atomic across filesystems and about race
conditions that can corrupt the queue; add a brief safety note instructing
maintainers to (1) prefer an atomic rename on the same filesystem or implement
an explicit locking/claim protocol (e.g., create a unique temporary/claim file
or use link+unlink or filesystem locks) to avoid collisions, (2) detect and
handle failures from mv/rename and retry/abort safely, and (3) fall back to an
explicit copy+atomic-rename pattern with checks when crossing filesystems to
prevent duplicate processing.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Added move safety guidance outlining atomic renames, copy+rename fallbacks, and error checks. |
>
> ## Lesson Learned
>
> Documenting filesystem safety prevents coordination races in SLAPS workflows.
>
> ## What did you do to address this feedback?
>
> Inserted safety bullets under step 2 in `docs/YOU ARE WORKER 6.rb:8-15` covering atomic rename preference, cross-filesystem copy+rename, and failure handling.
>
> ## Regression Avoidance Strategy
>
> Keep workflow docs updated as coordination tooling evolves to maintain safe task-claim semantics.
>
> ## Notes
>
> None.

### docs/YOU ARE WORKER 6.rb:26

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/YOU ARE WORKER 6.rb around lines 21 to 26, the example shell commands
use paths with spaces unquoted and a plain mv that can clobber files; update the
examples to quote all filesystem paths (e.g.
"slaps-coordination/open-tasks/P1.T001.json") and add the -n flag to mv (mv -n
"source" "dest/") to prevent overwriting; ensure any path that could be
interpreted as an option is protected by quoting or by using -- where
appropriate.
```

{response}

### auto_commit.sh:1

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In auto_commit.sh around line 1, the script lacks Bash strict mode which can
hide failures in the infinite git loop; add a strict-mode invocation immediately
after the shebang and set a safe IFS: enable errexit, errtrace, nounset and
pipefail (i.e. set -Eeuo pipefail) and set IFS to newline+tab so word-splitting
is safe; ensure this is the first executable code so the script exits on errors
and treats unset variables as failures.
```

{response}

### auto_commit.sh:6

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In auto_commit.sh around lines 4-6 (and similarly lines 45-47) the script starts
an unconditional infinite loop which can DOS CI; add a guard using an
environment variable (e.g., MAX_ITERATIONS) with a sensible default and an
iteration counter that increments each loop and breaks when the max is reached,
and add signal handling: install a trap for SIGINT and SIGTERM that sets a flag
(or exits) so the loop can terminate cleanly; ensure the loop checks the flag
before each iteration and after sleep, and prefer a configurable SLEEP_SECONDS
(default 300) so cadence remains adjustable.
```

{response}

### auto_commit.sh:41

- [ ] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In auto_commit.sh around lines 30 to 41, the script currently parses git push
output with grep which is brittle; instead call git rev-parse --abbrev-ref HEAD
to get the current branch, run git push origin <current-branch> (or git push
--set-upstream origin <current-branch> if upstream is not set) and check git’s
exit status ($?) to determine success; remove the grep pipeline and use the push
command’s exit code to log success or failure, and when upstream is unset detect
that (e.g., by checking git rev-parse --symbolic-full-name @{u} or examining
push exit code) and set upstream only when needed.
```

{response}

### config/config.example.yaml:2

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In config/config.example.yaml around line 2, the default Redis address is set to
"redis:6379" which breaks local development; change the default to
"localhost:6379" and add a one-line comment explaining that Docker Compose uses
the service name (e.g., redis:6379) and show an example override instruction
(mention using a compose-specific config or environment variable to set addr to
redis:6379 for containerized runs). Ensure the example indicates how to override
the value (compose config or env) and keep the default local-friendly value in
the example file.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Default now targets localhost with a comment noting Docker overrides. |
>
> ## Lesson Learned
>
> Ship examples with local-friendly defaults and document container overrides.
>
> ## What did you do to address this feedback?
>
> Updated the sample config to use `localhost:6379` and added a comment referencing Docker Compose overrides.
>
> ## Regression Avoidance Strategy
>
> Keep example configs matching the most common developer workflow and rely on env-specific overrides.
>
> ## Notes
>
> Config-only change.

### config/config.example.yaml:66

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In config/config.example.yaml around lines 50 to 66, the idempotency settings
lack precise semantics; update the example with comments that (1) define exactly
what constitutes the idempotency key (e.g., which headers and/or payload hash
are used and the format that fills {queue},{tenant},{key}), (2) describe
collision behavior (what happens when two requests produce the same key — e.g.,
first-wins, overwrite, or atomic check-and-set) and how retries interact with
stored results, (3) clarify TTL semantics versus cleanup_interval (TTL is how
long a record is valid; cleanup is periodic garbage collection and may not
immediately remove expired keys), and (4) note implications for storage options
(e.g., Redis hashes vs keys, compression effects) so users can configure
default_ttl, cleanup_interval, max_retries and retry_delay correctly.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Added inline comments covering key format, collision behaviour, and TTL vs cleanup semantics. |
>
> ## Lesson Learned
>
> Config samples should encode operational knowledge, not just values.
>
> ## What did you do to address this feedback?
>
> Documented the `{queue}:{tenant}:{key}` composition, first-write semantics, and clarified how cleanup differs from TTL.
>
> ## Regression Avoidance Strategy
>
> Continue annotating config examples when behaviour may surprise operators.
>
> ## Notes
>
> Comments only; no functional change.

### config/config.example.yaml:80

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In config/config.example.yaml around lines 67 to 80, the outbox section is
disabled and only notes "Requires database setup" without any example DB
configuration or usage guidance; add a commented example DSN and required
schema/table names (e.g., outbox table name, columns used), an example polling
query or SQL snippet, and recommended config knobs (connection string, table,
schema, retention/purge query) or a link to the docs page that defines the
outbox setup so users can enable and configure it easily.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Outbox config now includes sample DSN, table name, and polling query hints. |
>
> ## Lesson Learned
>
> Stub configs need actionable guidance so operators can enable features quickly.
>
> ## What did you do to address this feedback?
>
> Added commented DSN, table details, and example polling query fields to the outbox section.
>
> ## Regression Avoidance Strategy
>
> Keep optional modules documented inline with a pointer to deeper docs.
>
> ## Notes
>
> Comments only; no runtime logic affected.

### create_review_tasks.py:4

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In create_review_tasks.py around lines 1-4 and also update lines 102-112,
convert the script into a CLI tool by wrapping execution in if __name__ ==
'__main__' and adding argparse flags --limit (int) and --dir (path) to control
output quantity and directory; add an optional --timestamp flag (ISO8601 or
epoch) that, when provided, is used instead of datetime.now() so outputs are
deterministic for CI/tests; refactor functions that currently call
datetime.now() or use globals to accept a timestamp parameter (defaulting to
now) and ensure the main entry parses flags, injects the parsed timestamp into
those functions, and writes outputs to the specified dir with behavior unchanged
when flags are omitted.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Script now exposes argparse flags for limit, dirs, and timestamp with a guarded main entry. |
>
> ## Lesson Learned
>
> Turning helper scripts into CLIs makes them reusable in automation.
>
> ## What did you do to address this feedback?
>
> Rewrote `create_review_tasks.py` to parse CLI arguments, support deterministic timestamps, and route execution through `main()`.
>
> ## Regression Avoidance Strategy
>
> Keep future utility scripts structured around `argparse` to simplify testing.
>
> ## Notes
>
> Manual testing only.

### create_review_tasks.py:11

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In create_review_tasks.py around lines 9 to 11, the code calls
os.listdir(completed_dir) which will crash if completed_dir does not exist; add
a guard to check for directory existence (os.path.isdir or os.path.exists)
before listing, and either create the directory (os.makedirs(completed_dir,
exist_ok=True)) or skip processing when it’s missing; then proceed to iterate
over files only when the directory exists to avoid the crash.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Script now checks `os.path.isdir` before listing completed tasks. |
>
> ## Lesson Learned
>
> Guard filesystem access to keep automation resilient.
>
> ## What did you do to address this feedback?
>
> Added `load_completed_tasks` that returns an empty list when the directory is missing instead of raising.
>
> ## Regression Avoidance Strategy
>
> Wrap future directory scans in helper functions with existence checks.
>
> ## Notes
>
> No automated tests; behaviour verified manually.

### create_review_tasks.py:31

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In create_review_tasks.py around lines 30-31, the code constructs timestamps
with datetime.now().isoformat()+"Z" which produces a naive local time mislabeled
as UTC; change this to use an aware UTC timestamp by calling
datetime.now(timezone.utc).isoformat() (and add/import timezone from datetime if
missing) so the produced ISO string reflects real UTC (or, if you must keep the
trailing "Z", use datetime.now(timezone.utc).isoformat().replace("+00:00","Z")).
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Timestamps now derive from `datetime.now(timezone.utc)` and render with `Z`. |
>
> ## Lesson Learned
>
> Always emit UTC-aware timestamps when generating artefacts for coordination.
>
> ## What did you do to address this feedback?
>
> Added `parse_timestamp` and `isoformat_z` helpers to ensure timestamps are timezone-aware and deterministic.
>
> ## Regression Avoidance Strategy
>
> Stick to helper functions for formatting times to avoid naive/aware mix-ups.
>
> ## Notes
>
> Covered implicitly via manual CLI verification.

### demos/lipgloss-transformation.tape:142

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In demos/lipgloss-transformation.tape around lines 136-142 (and similarly for
147-162) you are scripting "Type" commands that will fail if the referenced
binary doesn’t exist; add a clear guard or disclaimer: check for the binary file
(e.g., test -x ./bin/queue-tui) before running the Type sequence and skip or
print an explanatory echo if missing, or replace the sequence with a
commented/echoed mock note indicating this is a scripted demo and not executed;
ensure the demo prints a clear message when skipped so users know why the
interactive steps weren’t run.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Tape now runs `if [ -x ./bin/queue-tui ]` before invoking the binary. |
>
> ## Lesson Learned
>
> VHS scripts should degrade gracefully on hosts lacking optional binaries.
>
> ## What did you do to address this feedback?
>
> Wrapped the TUI invocation in an executable check that prints a skip message when absent.
>
> ## Regression Avoidance Strategy
>
> Guard future demo commands with `command -v` or `test -x` to keep CI green.
>
> ## Notes
>
> Manual inspection only.

### demos/lipgloss-transformation.tape:276

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In demos/lipgloss-transformation.tape around lines 271 to 276, the script calls
figlet directly which will break on hosts without figlet; wrap the figlet
invocation in a guard that checks for the figlet binary (e.g., `command -v
figlet >/dev/null`) and, if missing, output a sensible fallback (plain "Redis
TUI" or a simple ASCII alternative) so the tape continues; apply the same
guarded pattern used elsewhere in the repo for the other figlet invocation.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | figlet call now wrapped in `command -v` test with plain-text fallback. |
>
> ## Lesson Learned
>
> Optional aesthetic dependencies must have graceful fallbacks in demos.
>
> ## What did you do to address this feedback?
>
> Replaced the direct figlet invocation with a guarded command that prints `Redis TUI` if figlet is unavailable.
>
> ## Regression Avoidance Strategy
>
> Guard all external demo tooling to prevent CI breakage.
>
> ## Notes
>
> Manual verification only.

### demos/responsive-tui.tape:278

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In demos/responsive-tui.tape around lines 271-278 the final figlet call can
throw when figlet isn’t installed; wrap the figlet invocation in a safe guard so
the demo won’t crash on clean systems by detecting availability (e.g., try/catch
around require/spawn or check for the binary) and providing a graceful fallback
(render plain text or a simpler ASCII header) when figlet isn’t present,
ensuring the tape continues without error.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Added guarded figlet call (with text fallback) to the responsive TUI summary segment. |
>
> ## Lesson Learned
>
> Even cosmetic commands should be optional in demos.
>
> ## What did you do to address this feedback?
>
> Inserted a `command -v figlet` check before rendering the closing banner, falling back to plain text when absent.
>
> ## Regression Avoidance Strategy
>
> Reuse this guard for future banner output in tapes.
>
> ## Notes
>
> Manual verification only.

### dependency_analysis.py:231

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In dependency_analysis.py around lines 7 to 231, feature keys use kebab-case
(e.g., "admin-api") while dependency lists use snake_case (e.g., "admin_api"),
causing resolution failures; normalize names to one canonical form (pick either
kebab-case or snake_case) at import by mapping all feature keys and all
dependency entries through the same normalizer (replace - with _ or vice versa)
before building the graph, correct known typos (e.g., change
"distributed_tracing" to "distributed-tracing-integration" or its normalized
equivalent), and add a validation pass that checks each dependency resolves to a
defined feature and logs or raises on unresolved refs so downstream DAGs fail
fast.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Added normalization helpers, alias mapping, infrastructure stubs, and a validation routine. |
>
> ## Lesson Learned
>
> Dependency data should expose a canonical view and fail fast on typos.
>
> ## What did you do to address this feedback?
>
> Added `normalize_name`, alias support, a richer infrastructure map, and `validate_dependencies()` which runs on script execution.
>
> ## Regression Avoidance Strategy
>
> Run the script to surface unresolved dependencies whenever updating the feature map.
>
> ## Notes
>
> No automated tests presently; validation ensures missing references raise immediately.

### docs/05_architecture.md:7

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/05_architecture.md around line 7, the architecture text omits the
exactly-once/idempotency component; update the paragraph to add an
“Exactly-once” component and describe its flows: record/check idempotency key at
job intake, guard worker processing with idempotency lookup, persist
side-effects to an outbox before acknowledging completion, and publish outbox
entries to external systems; also mention how the reaper and circuit breaker
interact with idempotency (do not double-process keys) and that observability
should include metrics/traces for idempotency/outbox operations.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Component list and data flows now call out the idempotency/outbox layer. |
>
> ## Lesson Learned
>
> Architecture docs should describe critical data integrity flows explicitly.
>
> ## What did you do to address this feedback?
>
> Added an "Exactly-once & Idempotency" component bullet and expanded the data flow steps to cover key persistence, outbox write, and reaper Lua requeueing.
>
> ## Regression Avoidance Strategy
>
> Keep architecture docs updated alongside major resilience features.
>
> ## Notes
>
> Documentation only.

### docs/06_technical_spec.md:129

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/06_technical_spec.md around lines 124-129 and also 131-134, the metrics
and logging section lacks explicit label names, cardinality bounds, unit
verification, and stable log key rules; update the doc to (1) list every metric
label schema (e.g., queue_length{queue}) and state a max cardinality or allowed
value set for each label, (2) verify and declare that the histogram metric uses
seconds (or rename suffix) so `_seconds` matches actual units, (3) state exact,
enforced log key names (trace_id, span_id, job_id, queue, worker_id) and forbid
logging secrets or PII, and (4) add a short note about how to enforce these
constraints in code/review (e.g., validation rules or linter/checklist).
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Spec now enumerates metric labels, units, and canonical log keys with guidance. |
>
> ## Lesson Learned
>
> Specifications should state exact metric schemas to keep implementations consistent.
>
> ## What did you do to address this feedback?
>
> Documented allowed labels, histogram units, and enforced log keys along with validation expectations.
>
> ## Regression Avoidance Strategy
>
> Reference the spec during review to ensure new metrics/logs comply.
>
> ## Notes
>
> Documentation only.

### docs/09_requirements.md:49

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/09_requirements.md around lines 43-49, the acceptance criteria are
currently vague; update them to (1) enumerate the exact metric names and
expected types exposed at /metrics (e.g., request_count: counter,
request_duration_seconds: histogram, job_queue_length: gauge,
worker_registered_total: gauge) so tests can verify them, (2) specify that
/readyz must return healthy only if a successful Redis PING is received and at
least one worker is registered (describe the exact probe: call Redis PING and
check worker registration API/state), and (3) require admin destructive commands
to prompt for confirmation interactively and also accept a --yes flag for
non-interactive runs; additionally require automated unit/integration tests that
assert metric names/types, the /readyz behavior under Redis failure and
no-worker conditions, and admin command behavior with and without --yes.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Acceptance criteria now spell out metric names, readiness semantics, and admin safeguards. |
>
> ## Lesson Learned
>
> Precise acceptance criteria drive better tests and operator expectations.
>
> ## What did you do to address this feedback?
>
> Expanded the section to enumerate required metrics, readiness checks, and confirmation behaviour for admin commands.
>
> ## Regression Avoidance Strategy
>
> Keep acceptance criteria updated as the surface area evolves so QA remains aligned.
>
> ## Notes
>
> Documentation only.

### docs/12_performance_baseline.md:28

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/12_performance_baseline.md around lines 26 to 28, the example starts a
Redis container without pinning a specific minor version and lacks teardown
steps; update the run command to use a fixed minor Redis tag (e.g.,
7.2.x-alpine) and add explicit cleanup commands (stop/remove or force remove) so
reviewers can reproduce results reliably and avoid leftover containers.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Baseline now pins Redis to 7.2.4-alpine and documents cleanup. |
>
> ## Lesson Learned
>
> Bench instructions should be reproducible and self-cleaning.
>
> ## What did you do to address this feedback?
>
> Updated the docker run command to use `redis:7.2.4-alpine` and documented `docker stop jobq-redis` for teardown.
>
> ## Regression Avoidance Strategy
>
> Pin external dependencies and include cleanup steps in future runbooks.
>
> ## Notes
>
> Documentation change only.

### docs/12_performance_baseline.md:33

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/12_performance_baseline.md around lines 31 to 33, the README tells users
to run Redis locally but the example/default config uses redis:6379 and
therefore mismatches; update the doc to explicitly instruct readers to set
redis.addr="localhost:6379" for this baseline (or update the example config to
use localhost:6379) so the instructions and config agree—prefer adding a
one-line note beneath the config block that says: "Note: set
redis.addr=\"localhost:6379\" if running Redis locally for this baseline."
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Documentation now highlights the localhost address needed for the baseline setup. |
>
> ## Lesson Learned
>
> Docs and configs must reinforce each other or readers get lost.
>
> ## What did you do to address this feedback?
>
> Added an explicit note under step 2 calling out `redis.addr="localhost:6379"` to align with the container instructions.
>
> ## Regression Avoidance Strategy
>
> Cross-check doc updates when changing defaults.
>
> ## Notes
>
> Documentation change only.

### docs/14_ops_runbook.md:26

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/14_ops_runbook.md around lines 21 to 26, replace the single unpinned
"docker build -t job-queue-system:local ." entry with a pinned, reproducible
multi-arch build and an alternative compose build flow: update the docs to show
a buildx command that specifies platforms (e.g., linux/amd64,linux/arm64), pins
base image via build args or explicit tags, enables inline cache
(BUILDKIT_INLINE_CACHE=1), and uses --pull (and --push if publishing) so images
are reproducible across architectures; also add a separate example showing how
to build the same image via docker compose build for parity with later compose
notes.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Ops runbook now documents buildx multi-arch builds and compose parity commands. |
>
> ## Lesson Learned
>
> Reproducible builds require pinned tags and explicit tooling.
>
> ## What did you do to address this feedback?
>
> Added a `docker buildx build` example with inline cache/pull flags and a companion `docker compose build` snippet.
>
> ## Regression Avoidance Strategy
>
> Keep operational docs aligned with the build process used in release pipelines.
>
> ## Notes
>
> Documentation update only.

### docs/14_ops_runbook.md:35

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/14_ops_runbook.md around lines 32 to 35, the env-var mapping description
is too vague; replace the hand-wavy “upper snake case replaces dots” with
explicit examples and parsing notes: add 1–2 concrete mappings (e.g.,
WORKER_COUNT -> worker.count and REDIS_ADDR -> redis.addr), show the
transformation rule (dots -> underscores, keys uppercased), and note how
booleans (true/false/1/0) and durations/times are parsed (e.g., "30s" ->
duration) and any required quoting; update the list to include these exact
mappings and parsing expectations so operators know how to set env vars
unambiguously.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 9 | Added explicit mapping examples and parsing notes for environment overrides. |
>
> ## Lesson Learned
>
> Concrete examples beat vague prose in ops guides.
>
> ## What did you do to address this feedback?
>
> Documented `WORKER_COUNT`, `REDIS_ADDR`, and duration parsing expectations in the overrides section.
>
> ## Regression Avoidance Strategy
>
> Update example mappings whenever new config keys are introduced.
>
> ## Notes
>
> Documentation change only.

### docs/14_ops_runbook.md:42

- [x] Fixed
- [ ] Test Written
- [ ] Suggestion Ignored

```text
In docs/14_ops_runbook.md around lines 38 to 42, the guidance currently
documents /healthz, /readyz, /metrics but doesn't instruct how to restrict
access; update this section to recommend binding health/metrics endpoints to
localhost or a dedicated admin interface, or expose them on a separate
port/interface, and add explicit protection guidance: enforce network
policies/firewall rules to restrict access, require authentication/authorization
(mTLS, bearer tokens or HTTP basic+IP allowlist) for admin/metrics endpoints,
and note Prometheus should scrape via a securely proxied or authenticated
endpoint; keep the examples concise and state to avoid exposing these endpoints
on public listeners.
```

> [!note]- **Accepted**
> | Confidence | Remarks |
> |------------|---------|
> | 8 | Ops runbook now calls out binding metrics/health endpoints to controlled interfaces and restricting access. |
>
> ## Lesson Learned
>
> Observability endpoints must be secured like any other admin surface.
>
> ## What did you do to address this feedback?
>
> Added guidance to bind to localhost/admin interfaces and to enforce network policies or auth for `/metrics` and health checks.
>
> ## Regression Avoidance Strategy
>
> Revisit security guidance whenever adding new operational endpoints.
>
> ## Notes
>
> Documentation-only change.
