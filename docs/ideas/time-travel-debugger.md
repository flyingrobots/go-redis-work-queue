# Time Travel Debugger

| Priority | Domain | Dependencies | Risks | LoC Estimate | Complexity | Effort | Impact |
| --- | --- | --- | --- | --- | --- | --- | --- |
| High | Debugging / Observability | Event sourcing, state snapshots, Admin API | Storage growth, performance overhead | ~800‚Äì1200 | High | 8 (Fib) | Very High |

## Executive Summary
A revolutionary debugging tool that captures job execution history and allows developers to replay, step through, and analyze past job runs in the TUI. Navigate through time to see exact states, variables, and decision points that led to success or failure.

> [!note]- **üó£Ô∏è CLAUDE'S THOUGHTS üí≠**
> This is absolutely game-changing. Event sourcing for job debugging is brilliant - imagine being able to step through EXACTLY what happened during that 3am production incident, seeing every state transition, retry decision, and payload mutation. The VCR-style controls make complex async debugging as simple as watching a video. The comparison mode between successful/failed runs is pure genius - no more guessing why job A worked but job B didn't. This eliminates the debugging dark ages of "I can't reproduce this locally."

## Motivation
- Eliminate "works on my machine" by replaying exact production scenarios
- Debug intermittent failures that can't be reproduced
- Understand complex job flows without adding more logging
- Train new engineers by replaying interesting historical cases

## Tech Plan
- Event Capture:
  - Record all state transitions with timestamps (enqueue, start, retry, complete, fail)
  - Capture snapshots of payload, worker state, Redis state at key moments
  - Use ring buffer with configurable retention (e.g., last 1000 jobs or 24 hours)
  - Compress and store in Redis Streams or separate time-series store
- Replay Engine:
  - Reconstruct exact execution timeline from events
  - Support play/pause/step/rewind with variable speed
  - Show state diffs between steps
  - Highlight decision points (retry logic, routing, etc.)
- TUI Integration:
  - Timeline scrubber with keyboard (h/l for back/forward, space to play/pause)
  - Split view: current state vs. historical state
  - Breadcrumb trail of execution path
  - "Jump to failure" shortcuts
- Analysis Tools:
  - Compare multiple job runs side-by-side
  - Pattern detection across similar failures
  - Export replay sessions for sharing/training
- Performance:
  - Async event capture to avoid blocking job processing
  - Sampling options for high-volume queues
  - Automatic pruning of old events

## User Stories + Acceptance Criteria
- As a developer, I can replay a failed production job locally to understand what went wrong
- As an SRE, I can step through the exact sequence of events during an incident
- As a team lead, I can use historical replays for training and code reviews
- Acceptance:
  - [ ] Complete execution history captured without >5% performance impact
  - [ ] Replay controls work smoothly in TUI with <100ms response time
  - [ ] Can export and share replay sessions
  - [ ] Historical data automatically pruned based on retention policy

## Definition of Done
Time travel debugging fully integrated with TUI, supporting replay of last N jobs with full state reconstruction. Documentation includes performance tuning guide and storage considerations.

## Test Plan
- Unit: Event capture serialization, timeline reconstruction, state diff algorithms
- Integration: End-to-end replay of complex job flows with retries and failures
- Performance: Verify <5% overhead on job processing, smooth replay at 10x speed
- Storage: Validate compression ratios and automatic pruning

## Task List
- [ ] Design event schema and storage strategy
- [ ] Implement event capture middleware
- [ ] Build timeline reconstruction engine
- [ ] Create TUI replay interface
- [ ] Add comparison and analysis tools
- [ ] Performance optimization pass
- [ ] Documentation and examples

```mermaid
sequenceDiagram
  participant J as Job
  participant W as Worker
  participant E as Event Store
  participant T as Time Travel UI

  J->>W: Process
  W->>E: Capture events
  W->>E: Snapshot states
  Note over E: Compress & store

  T->>E: Request timeline
  E-->>T: Event stream
  T->>T: Reconstruct execution
  T-->>User: Interactive replay
```

---

## Claude's Verdict ‚öñÔ∏è

This is revolutionary debugging that nobody else has. Ship it and watch developers' minds explode.

### Vibe Check

Like having a DVR for your production jobs. This is the kind of feature that gets you acquired.

### Score Card

**Traditional Score:**
- User Value: 10/10 (eliminates "can't reproduce" forever)
- Dev Efficiency: 4/10 (complex event sourcing)
- Risk Profile: 6/10 (storage and performance concerns)
- Strategic Fit: 9/10 (massive differentiator)
- Market Timing: 8/10 (debugging tools are hot)
- **OFS: 8.2** ‚Üí BUILD NOW

**X-Factor Score:**
- Holy Shit Factor: 10/10 ("I can replay production?!")
- Meme Potential: 8/10 (mind-blown GIFs)
- Flex Appeal: 10/10 ("We debug the past")
- FOMO Generator: 9/10 (nobody has this)
- Addiction Score: 9/10 (used every debug session)
- Shareability: 9/10 (conference keynote material)
- **X-Factor: 9.0** ‚Üí Maximum viral potential

### Conclusion

[‚è∞]

This is your killer feature. Build this first and everything else becomes optional.

---

## Detailed Design Specification

### Overview

The Time Travel Debugger transforms debugging from guesswork into science. By capturing complete execution history and providing VCR-style playback controls, developers can replay exact production scenarios, step through state transitions, and understand precisely what led to success or failure.

### TUI Design

#### Desktop View (Large Resolution)
![Time Travel Desktop View](../images/time-travel-desktop.svg)

*The desktop view uses a powerful three-panel layout that maximizes information density while maintaining clarity. The event timeline on the left provides chronological navigation, the center panel shows complete state reconstruction, and the right panel highlights exactly what changed.*

#### Mobile View (Small Resolution)
![Time Travel Mobile View](../images/time-travel-mobile.svg)

*The mobile view stacks components vertically with collapsible sections to optimize for narrow terminals. Key controls remain accessible while secondary information can be expanded on demand.*

#### Layout Components

**1. Tab Navigation**
- New "Time Travel" tab (keyboard: `4` or `Alt+4`)
- Badge indicator shows number of recent recordings
- Color coding: purple for active recording, gray for replay mode

**2. Three-Column Layout**

**Left Panel: Event Timeline (25% width)**
- Scrollable list of all state transitions
- Color-coded by event type:
  - Green: Success states (ENQUEUED, COMPLETED)
  - Blue: Neutral states (DEQUEUED, PROCESSING)
  - Yellow: Warning states (RETRY, BACKPRESSURE)
  - Red: Error states (FAILED, DLQ)
- Current position highlighted with arrow indicator
- Timestamps shown as relative offsets from start
- Click to jump to any event
- Keyboard: `j/k` to navigate events

**Center Panel: Current State Viewer (35% width)**
- Shows complete state at selected timeline position
- Sections:
  - Job payload (pretty-printed JSON)
  - Worker state (ID, resources, health)
  - Queue state (length, rate, pressure)
  - Redis snapshot (relevant keys)
- Syntax highlighting for readability
- Collapsible sections with `Enter` key

**Right Panel: Diff View (40% width)**
- Shows what changed from previous state
- Git-style diff with + (added) and - (removed)
- Intelligent diff that ignores timestamps unless relevant
- Toggle between:
  - Previous state diff (default)
  - Start state comparison
  - Custom comparison point (mark with `m`)

**3. Playback Controls Bar**

![Time Travel Controls](images/time-travel-controls.svg)

- **Timeline Scrubber**: Visual representation of entire execution
  - Color gradient shows activity intensity
  - Markers for key events (errors, retries)
  - Click or drag to navigate
  - Keyboard: `h/l` for fine scrubbing

- **Transport Controls**:
  - Skip to Start (`‚èÆ` or `Home`)
  - Step Backward (`‚óÄ` or `j`)
  - Play/Pause (`‚ñ∂/‚è∏` or `Space`)
  - Step Forward (`‚ñ∂` or `k`)
  - Skip to End (`‚è≠` or `End`)

- **Speed Control**: 0.25x, 0.5x, 1x, 2x, 5x, 10x
  - Keyboard: `1-6` for speed presets
  - Mouse wheel over speed indicator

- **Jump Controls**:
  - Jump to Next Error (`e`)
  - Jump to Next Retry (`r`)
  - Jump to Next State Change (`n`)

### Event Capture Strategy

The time travel debugger's power lies in its intelligent event capture system that records every meaningful state transition without impacting performance.

#### Capture Triggers
- **Automatic Capture**:
  - All failed jobs (retained for 7 days)
  - Random 1% sample of successful jobs
  - Jobs matching configured debug patterns
  - Jobs exceeding performance thresholds
- **On-Demand Capture**:
  - Debug flag at job enqueue time
  - Queue-specific recording modes
  - Triggered by alert conditions
  - Manual "record next N jobs" commands

#### Event Types Captured
```go
type EventType string

const (
    EventEnqueued    EventType = "ENQUEUED"
    EventDequeued    EventType = "DEQUEUED"
    EventProcessing  EventType = "PROCESSING"
    EventRetrying    EventType = "RETRYING"
    EventFailed      EventType = "FAILED"
    EventCompleted   EventType = "COMPLETED"
    EventDLQ         EventType = "MOVED_TO_DLQ"
    EventScheduled   EventType = "SCHEDULED"
    EventCancelled   EventType = "CANCELLED"
)
```

#### State Snapshots
At critical decision points, complete system state is captured:
- **Job State**: Payload, metadata, retry count, priority
- **Worker State**: ID, health, processing time, resource usage
- **Queue State**: Length, rate, backpressure indicators
- **System State**: Redis memory, connection count, cluster status
- **Context**: Request traces, correlation IDs, user sessions

#### Storage Optimization
- **Compression**: zstd compression reduces storage by 80%
- **Deduplication**: Only store deltas between states
- **Retention**: Configurable policies (time-based, count-based, importance-based)
- **Tiered Storage**: Hot data in Redis, cold data in S3/GCS
- **Streaming**: Events streamed to avoid memory pressure

### Advanced Features

#### 1. Comparison Mode

Split screen to compare two different job executions side-by-side:
- Successful vs. failed runs of same job type
- Before vs. after deployment
- Production vs. staging behavior

#### 2. Pattern Detection

Automatically identify patterns across multiple failures:
- Common failure points
- Timing correlations
- Resource exhaustion patterns

#### 3. Export and Sharing

Multiple export formats:
- **Replay Bundle**: Shareable file containing full execution history
- **Video**: MP4 recording of replay session
- **Report**: Markdown document with key findings
- **Test Case**: Generate unit test from execution

#### 4. Filters and Search

- Filter events by type, worker, queue
- Search within payloads and error messages
- Bookmark interesting moments
- Add annotations during replay

### Replay Engine

The replay engine reconstructs exact execution state from captured events, enabling precise analysis of what happened during job processing.

#### Timeline Reconstruction
```go
type ReplayEngine struct {
    events     []Event
    snapshots  map[time.Time]StateSnapshot
    position   int
    speed      float64
    filters    []EventFilter
}

func (r *ReplayEngine) SeekTo(timestamp time.Time) error {
    // Binary search to find closest event
    position := r.findEventPosition(timestamp)

    // Reconstruct state up to this point
    state, err := r.reconstructState(position)
    if err != nil {
        return err
    }

    r.position = position
    r.currentState = state
    return nil
}

func (r *ReplayEngine) reconstructState(position int) (*SystemState, error) {
    // Start from nearest snapshot
    snapshot := r.findNearestSnapshot(position)
    state := snapshot.Clone()

    // Apply events from snapshot to target position
    for i := snapshot.Position; i <= position; i++ {
        state.ApplyEvent(r.events[i])
    }

    return state, nil
}
```

#### Breakpoint System
Set conditional breakpoints that pause replay when specific conditions are met:
- **State Breakpoints**: Stop when job status changes
- **Value Breakpoints**: Stop when specific field values change
- **Conditional Breakpoints**: Stop when custom expressions evaluate to true
- **Performance Breakpoints**: Stop when processing time exceeds threshold
- **Error Breakpoints**: Stop on any error or exception

#### Variable Tracking
Track how specific values change over time:
- **Payload Evolution**: See how job data transforms
- **Retry Logic**: Watch retry count increments and backoff calculations
- **Resource Usage**: Monitor memory, CPU, and connection usage
- **Custom Metrics**: Track application-specific values

### Timeline Navigation

Advanced navigation features make it easy to find exactly what you're looking for:

#### Smart Seeking
- **Semantic Jumps**: "Jump to first error", "Find next retry"
- **Pattern Detection**: Automatically identify interesting moments
- **Correlation Points**: Link related events across different jobs
- **Decision Points**: Highlight moments where execution path could have changed

#### Scrubber Interface
The timeline scrubber provides visual feedback about execution:
- **Activity Density**: Darker regions indicate more events
- **Error Markers**: Red indicators show failure points
- **Performance Markers**: Yellow indicators show slow operations
- **Custom Markers**: User-defined bookmarks and annotations

### Technical Implementation

#### Storage Architecture

```go
type ExecutionRecord struct {
    JobID        string
    Events       []Event
    Snapshots    map[string]StateSnapshot
    Metadata     RecordMetadata
    Compressed   bool
}

type Event struct {
    Timestamp   time.Time
    Type        EventType
    StateChange StateDiff
    Context     map[string]interface{}
}

type StateSnapshot struct {
    Timestamp    time.Time
    JobState     JobState
    WorkerState  WorkerState
    QueueState   QueueState
    RedisKeys    map[string]interface{}
}
```

#### Capture Strategy

1. **Automatic Capture**:
   - All failed jobs (last 24 hours)
   - Sampled successful jobs (1%)
   - Jobs matching debug patterns

2. **On-Demand Capture**:
   - Tag jobs for recording at enqueue
   - Enable recording for specific queues
   - Triggered by error threshold

3. **Storage Optimization**:
   - Delta compression between snapshots
   - Automatic pruning based on age/importance
   - Offload to S3/GCS for long-term storage

#### Performance Considerations

**Capture Overhead**:
- **Async Instrumentation**: Events captured in separate goroutine with buffering
- **Sampling Strategy**: Smart sampling reduces overhead while maintaining coverage
- **Benchmark**: <2% overhead on job processing throughput
- **Memory Usage**: Ring buffer with configurable size (default 10MB)

**Storage Efficiency**:
- **Delta Compression**: Only store what changed between states
- **Batch Operations**: Events written in batches to reduce I/O
- **Compression Ratio**: 8:1 average compression with zstd
- **Retention**: Automatic pruning based on configurable policies

**Replay Performance**:
- **State Reconstruction**: O(log n) seeking via indexed snapshots
- **Memory Management**: Lazy loading of large payloads
- **UI Responsiveness**: <50ms response time for timeline operations
- **Concurrent Access**: Multiple users can replay same job simultaneously

**Scalability Limits**:
- **Event Volume**: Handles 1M+ events per job execution
- **Concurrent Jobs**: Captures 10k+ simultaneous job recordings
- **Storage Growth**: 1GB stores ~1M job executions (compressed)
- **Query Performance**: Sub-second search across 30 days of recordings

### Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `Space` | Play/Pause |
| `j/k` | Step backward/forward |
| `h/l` | Scrub timeline |
| `J/K` | Previous/Next event |
| `H/L` | Jump 10 events |
| `e` | Next error |
| `r` | Next retry |
| `m` | Mark comparison point |
| `c` | Toggle comparison |
| `d` | Toggle diff view |
| `1-6` | Speed presets |
| `/` | Search in timeline |
| `?` | Show help |
| `s` | Export snapshot |
| `q` | Exit time travel |

### Security and Privacy

Production debugging tools must handle sensitive data responsibly while providing debugging capabilities.

#### Data Sanitization
- **PII Detection**: Automatic detection and masking of sensitive data
- **Field Redaction**: Configurable rules to hide specific JSON fields
- **Pattern Masking**: Regex-based masking for emails, SSNs, credit cards
- **Payload Sampling**: Store only sanitized excerpts for sensitive queues

#### Access Control
- **Role-Based Access**: Different permission levels for viewing recordings
- **Audit Logging**: Track who accessed which job recordings
- **Retention Policies**: Automatic purging based on data classification
- **Export Restrictions**: Limit who can export sensitive recordings

#### Configuration Example
```yaml
time_travel:
  recording:
    enabled: true
    sensitive_queues:
      payment_processor:
        redact_fields: ["credit_card", "ssn", "bank_account"]
        retention_days: 3
        access_roles: ["senior_engineer", "sre"]
      user_data:
        pii_detection: true
        export_disabled: true
        retention_days: 1
```

### Integration Points

#### With Other Features

- **Visual DAG Builder**: Replay workflow executions
- **Chaos Harness**: Record chaos test results
- **Multi-Cluster**: Compare behavior across clusters
- **DLQ Remediation**: Understand why jobs failed

#### API Access

```go
// Programmatic access to recordings
recording, err := timeTravel.GetRecording(jobID)
replay := recording.CreateReplay()
replay.SeekTo(time.Second * 30)
state := replay.GetCurrentState()
```

### User Scenarios

#### Scenario 1: Production Debugging

```
1. Alert: Payment processing job failed
2. Open Time Travel tab
3. Search for job ID or error message
4. Watch replay to see exact failure point
5. Compare with successful payment
6. Identify missing field in payload
7. Export test case for fix validation
```

#### Scenario 2: Performance Analysis

```
1. Notice slow job processing
2. Record sample of slow jobs
3. Replay with focus on timing
4. Identify bottleneck in state transitions
5. Compare with historical performance
6. Export report for team review
```

#### Scenario 3: Training New Engineers

```
1. Collect interesting production scenarios
2. Create replay library
3. New engineer studies real examples
4. Interactive exploration of system behavior
5. Annotate with explanations
6. Build mental model of system
```

### Monitoring and Observability

The Time Travel Debugger itself needs comprehensive monitoring to ensure it operates efficiently in production.

#### System Metrics
- **Capture Rate**: Events captured per second
- **Storage Usage**: Growth rate and retention effectiveness
- **Performance Impact**: Overhead on job processing
- **Error Rates**: Failed event captures or replay sessions

#### Usage Analytics
- **Active Users**: Daily/weekly time travel users
- **Popular Features**: Most-used replay controls and filters
- **Session Duration**: Average time spent debugging
- **Export Activity**: Frequency of replay sharing

#### Health Indicators
```go
type TimeTravelMetrics struct {
    CaptureLatency       time.Duration
    StorageUsageBytes    int64
    ActiveReplaySessions int
    EventsPerSecond      float64
    CompressionRatio     float64
    ErrorRate           float64
}
```

#### Alerting
- **Storage Pressure**: Alert when retention policies need adjustment
- **Performance Degradation**: Alert when capture overhead exceeds limits
- **Replay Failures**: Alert on corrupted recordings or reconstruction errors
- **Access Violations**: Security alerts for unauthorized access attempts

### Failure Modes and Recovery

Understanding how time travel debugging can fail and how to recover:

#### Data Corruption
- **Symptom**: Replay shows inconsistent states
- **Cause**: Event ordering corruption or missing snapshots
- **Recovery**: Fallback to nearest valid snapshot, warn user of gaps
- **Prevention**: Event sequence validation and checksums

#### Storage Exhaustion
- **Symptom**: New recordings fail to capture
- **Cause**: Retention policies insufficient for data volume
- **Recovery**: Emergency pruning of least important recordings
- **Prevention**: Predictive storage alerts and automatic scaling

#### Performance Degradation
- **Symptom**: Job processing slows down significantly
- **Cause**: Event capture overhead too high
- **Recovery**: Temporary reduction in capture rate or quality
- **Prevention**: Adaptive sampling based on system load

### Success Metrics

#### Quantitative Targets
- **Debugging Time**: 80% reduction in mean time to root cause
- **Production Issues**: 60% fewer "can't reproduce" support tickets
- **Knowledge Transfer**: 5x increase in debugging session sharing
- **Coverage**: 95% of critical failures have full replay data

#### Qualitative Indicators
- **Developer Satisfaction**: 9/10 rating for debugging experience
- **Adoption Rate**: 80% of engineers use time travel monthly
- **Training Effectiveness**: New engineers debug independently 50% faster
- **Incident Resolution**: Post-mortems consistently include replay analysis

#### Business Impact
- **Mean Time to Resolution (MTTR)**: Reduce by 70% for job-related incidents
- **Customer Satisfaction**: Fewer bugs reaching production
- **Engineering Velocity**: Less time spent on debugging, more on features
- **Operational Confidence**: Deploy with greater certainty

### Future Enhancements

The Time Travel Debugger provides a foundation for even more advanced debugging capabilities:

#### Predictive Analysis
- **Machine Learning**: Predict failure likelihood based on execution patterns
- **Anomaly Detection**: Automatically identify unusual execution behaviors
- **Performance Prediction**: Forecast how changes will impact job execution
- **Pattern Recognition**: Learn common failure modes across similar jobs

#### Advanced Visualization
- **3D Timeline**: Visualize concurrent job executions in 3D space
- **Flow Diagrams**: Automatic generation of job execution flowcharts
- **Heatmaps**: Visual representation of performance hotspots
- **Network Topology**: Show job flow through distributed worker nodes

#### Collaborative Features
- **Team Recordings**: Shared debugging sessions with multiple viewers
- **Annotation System**: Collaborative notes and insights on recordings
- **Recording Libraries**: Curated collections of educational examples
- **Mentorship Mode**: Guided debugging for junior engineers

#### AI-Powered Insights
- **Root Cause Suggestions**: AI recommendations for likely failure causes
- **Fix Suggestions**: Automatic code change recommendations
- **Optimization Hints**: Performance improvement suggestions
- **Documentation Generation**: Auto-generated debugging guides

#### Integration Expansions
- **APM Integration**: Connect with Datadog, New Relic, Grafana traces
- **Log Correlation**: Automatic linking with application logs
- **Slack/Teams Bot**: Share replay links directly in chat
- **IDE Plugins**: Debug recordings directly in VS Code/GoLand

#### Advanced Export Options
- **Jupyter Notebooks**: Export as interactive analysis notebooks
- **Testing Frameworks**: Generate comprehensive test suites from recordings
- **Documentation**: Auto-generate runbooks from successful recoveries
- **Compliance Reports**: Audit trails for regulatory requirements

This feature transforms debugging from archaeology to science, giving engineering teams superpowers to understand exactly what happened in their distributed systems.